{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An example of an RV analysis including a GP treatment of stellar activity\n",
    "\n",
    "The following is an example of how I typically approach modelling an RV time series that is known to contain at least one transiting planet plus stellar activity. The intention is to illustrate the steps that I take to go from the input time series to physical models of planetary signals and a probabilistic model of stellar activity in the form of a 1d Gaussian process. Hopefully you find the instructions herein useful if you are new to RV data analysis.\n",
    "\n",
    "In this example we'll consider the published data of the two-planet system around the nearby M dwarf K2-18 (https://arxiv.org/abs/1707.04292). \n",
    "\n",
    "## Step 1: visualize the RVs and identify significant periodic signals\n",
    "\n",
    "Let's begin by first reading in the HARPS RV time series and visualizing the data and its generalized Lomb-Scargle periodogram to identify significant periodicities in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import george, emcee, bgls, time, warnings, corner\n",
    "from scipy.signal import medfilt        # median filter\n",
    "from scipy.interpolate import interp1d  # 1d interpolation\n",
    "from scipy.stats import gaussian_kde    # kernel density estimations\n",
    "from rvcurve import RV as kep_model     # compute Keplerian planet models\n",
    "from PyAstronomy.pyasl import foldAt    # phase-fold time series\n",
    "from uncertainties import unumpy as unp # propagating Gaussian uncertainties\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in HARPs time series\n",
    "d = np.loadtxt('./input_data/2M1130+0735_05052017_w7s5c5_NAIRA_v1.rdb', skiprows=2)\n",
    "bjd, rv, erv = d[:,:3].T   # only read in the RV time series and its uncertainties\n",
    "bjd += 2.4e6   # convert to barycentric julian date\n",
    "rv *= 1e3      # km/s -> m/s\n",
    "erv *= 1e3     # km/s -> m/s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we should inspect the RVs themselves for the sake of transparency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize RVs\n",
    "global t0\n",
    "t0 = 245e4\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.errorbar(bjd-t0, rv, erv, fmt='ko', elinewidth=.9)\n",
    "plt.xlabel('Time [BJD - %i]'%t0, fontsize=12)\n",
    "plt.ylabel('RV [m/s]', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the RVs look reasonable in that there are no obvious outliers. Furthermore, we can see that the star was observed by HARPS over three distinct observing windows each separated by $\\sim$ 200 days or $\\sim$ 6-7 months.\n",
    "\n",
    "Next let's plot the Bayesian generalized Lomb-Scargle (BGLS) periodogram (https://arxiv.org/abs/1412.0467) and highlight the periodic signal from the known transiting sub-Neptune K2-18b at $\\sim$ 33 days. Since we know that this system hosts a planet whose orbital period is $\\sim$ 33 days, we expect a periodic signal to exist in the RVs at that period assuming that the time series contains a sufficient number of measurements (it does) and the expected amplitude of the planetary signal is at least comparable to the typical RV uncertainties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pb, T0b = 32.93963, 2456836.1849   # period and mid-transit time of the transiting planet from the K2 light curve\n",
    "per, pwr = bgls.bgls(bjd, rv, erv, plow=.5, phigh=1e3, n_steps=1e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the BGLS\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(per, np.log(pwr), 'k-')\n",
    "plt.axvline(Pb, ls='--', lw=.9, color='b', label='K2-18b')\n",
    "plt.xscale('log'), plt.xlabel('Period [days]', fontsize=12)\n",
    "plt.ylabel('p(P|RV)', fontsize=12)\n",
    "plt.legend(loc='upper right', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A number of significant peaks can be seen in the BGLS periodogram. The least interesting ones are the aliases close to 1 day and half a day that are always present in RV time series and results from the fact that the instrument is on the ground and is rotating relative to the distant stars with a period of 1 day (the signal at half a day is the first harmonic of 1 day).\n",
    "\n",
    "The more interesting signals are<br>\n",
    "\n",
    "1) a strong peak at $\\sim$ 9 days which is likely due to a non-transiting planet in this system and<br>\n",
    "2) a pair of peaks surrounding the transiting planet's orbit period of 33 days.<br>\n",
    "\n",
    "It turns out that the joint peaks around 33 days may also be attributed to stellar rotation as well as to the RV signal from the known transiting planet. Let's confirm this by considering the star's K2 light curve from which the photometric rotation period can be measured.\n",
    "\n",
    "## Step 2: visualize the K2 photometry of K2-18\n",
    "\n",
    "Specifically the cleaned K2 photometry from the EVEREST light curve extraction pipeline (https://archive.stsci.edu/prepds/everest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the cleaned K2 photometry from the EVEREST pipeline\n",
    "bjdK2, flux, eflux = np.load('input_data/k218_k2_photometry.npy').T\n",
    "bjdK2 += 2454833  # convert the barycentric julian date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate points in and out of transit (in-transit points are identified by eye)\n",
    "transit_indices = np.append(np.arange(1201,1207), np.arange(2602,2610))\n",
    "intransit = np.in1d(np.arange(bjdK2.size), transit_indices)\n",
    "outtransit = np.invert(intransit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the light curve and highlight the transits\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.errorbar(bjdK2-t0, flux, eflux, fmt='k.', elinewidth=.9, alpha=.4)\n",
    "plt.plot(bjdK2[outtransit]-t0, medfilt(flux[outtransit],9)+4e-3, 'k--', lw=.9, \n",
    "         label='median filtered\\nphotometry + offset')\n",
    "plt.plot(bjdK2[intransit]-t0, flux[intransit], 'bo', ms=8, label='in-transit points')\n",
    "for i in range(2):\n",
    "    plt.axvline(T0b+i*Pb-t0, ls='-', lw=3, color='b', ymax=.05, label='K2-18b transits')\n",
    "    plt.axvline(T0b+i*Pb-t0, ls='-', lw=3, color='b', ymin=.95)\n",
    "plt.ylim((.989,1.014))\n",
    "plt.xlabel('Time [BJD - %i]'%t0, fontsize=12)\n",
    "plt.ylabel('Normalized Flux', fontsize=12)\n",
    "plt.legend(loc='upper left', fontsize=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline of the K2 photometry only lasts for 80 days. Within that time we can clearly see large-scale photometric variations with a period of $\\sim$ 40 days which is due to active regions (e.g. star spots) on the surface of K2-18 rotating in and out of view at the stellar rotation period. Two transits of K2-18b are also observed and are separated by the planet's orbital period of $\\sim$ 33 days.\n",
    "\n",
    "Also depicted is the median filtered photometry, with transits removed, and offset for clarity. This smoothed light curve will be useful when fitting the photometry.\n",
    "\n",
    "## Step 3: fit the photometry with a quasi-periodic Gaussian process\n",
    "\n",
    "Gaussian processes are a non-parametric set of model functions that are well-suited to modelling stochastic processes like the stellar activity that gives rise to the photometric variations observed for K2-18. Details of Gaussian processes (GPs) as they pertain to modelling stellar activity can be found in Chapter 2.2 of my thesis (*link pending*).\n",
    "\n",
    "We will use the $\\texttt{george}$ package to construct our GPs and perform the necessary matrix algebra. A description and examples of how to use $\\texttt{george}$ can be found here: https://george.readthedocs.io/en/latest/.\n",
    "\n",
    "Next we define the functions needed to compute the GP model and run an MCMC using the $\\texttt{emcee}$ package (https://arxiv.org/abs/1202.3665). Details on how to work with $\\texttt{emcee}$ can be found here: http://dfm.io/emcee/current/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phot_model(theta, bjd, flux, eflux, bjdpred=[]):\n",
    "    '''Compute GP model given the input photometry.'''\n",
    "    # sanity checks\n",
    "    assert len(theta) == 5                      # need five hyperparameters {lna, lnlambda, lnGamma, lnP, s}\n",
    "    assert bjd.size == flux.size == eflux.size  # all time series vectors must have the same length\n",
    "    assert np.all(np.isfinite(bjd+flux+eflux))  # all vector values must be finite (i.e. no NaNs or infs)\n",
    "    \n",
    "    # warning message\n",
    "    if bjd.size >= 1e3: \n",
    "        message = '\\nLarge time series are expensive to model with Gaussian processes. The input data contains ' + \\\n",
    "        '%i measurements. Consider binning the input data first.'%(bjd.size)\n",
    "        warnings.warn(message)\n",
    "    \n",
    "    # define the GP prior\n",
    "    agp, lgp, Ggp, Pgp, s = np.exp(theta)\n",
    "    k_sqexp = george.kernels.ExpSquaredKernel(lgp)    # squared exponential kernel\n",
    "    k_per = george.kernels.ExpSine2Kernel(Ggp, Pgp)   # periodic kernel\n",
    "    gp = george.GP(agp * (k_sqexp + k_per))           # quasi-periodic kernel\n",
    "    \n",
    "    # compute the covariance matrix\n",
    "    try:\n",
    "        gp.compute(bjd, np.sqrt(eflux**2 + s**2))\n",
    "    except (ValueError, np.linalg.LinAlgError):\n",
    "        return -np.inf\n",
    "    \n",
    "    # compute the mean and standard deviation of the GP posterior\n",
    "    bjdpred = bjdpred if len(bjdpred) > 0 else bjd\n",
    "    mu, cov = gp.predict(flux, bjdpred)\n",
    "    sig = np.sqrt(np.diag(cov))\n",
    "    \n",
    "    return gp, bjdpred, mu, sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnlike_K2(theta, bjd, flux, eflux):\n",
    "    '''Compute the ln likelihood of the K2 photometry modelled with a quasi-periodic GP regression model.'''\n",
    "    gp,_,_,_ = phot_model(theta, bjd, flux, eflux)\n",
    "    return gp.lnlikelihood(flux, quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnprior_K2(theta):\n",
    "    '''Compute the prior on the GP hyperparameters. This function assumes that the priors are uniform in log space \n",
    "    for all parameters.'''\n",
    "    # sanity check\n",
    "    assert len(theta) == 5\n",
    "    \n",
    "    # compute the prior for each hyperparameter\n",
    "    lnagp, lnlgp, lnGgp, lnPgp, lns = theta\n",
    "    lnpriors = np.zeros(5)\n",
    "    lnpriors[0] = lnuniform(lnagp, -20, 0)\n",
    "    lnpriors[1] = lnuniform(lnlgp, 0, 10)\n",
    "    lnpriors[2] = lnuniform(lnGgp, -5, 5)\n",
    "    lnpriors[3] = lnuniform(lnPgp, np.log(30), np.log(50))   # narrow this prior because we want to focus on Prot\n",
    "    lnpriors[4] = lnuniform(lns, -20, 0)\n",
    "    \n",
    "    # return the prior\n",
    "    return np.sum(lnpriors)\n",
    "\n",
    "    \n",
    "def lnuniform(val, min_val, max_val):\n",
    "    '''Define the uniform prior and return the log of its value.'''\n",
    "    assert max_val > min_val\n",
    "    return 1./(max_val-min_val) if min_val <= val <= max_val else -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnprob_K2(theta, bjd, flux, eflux):\n",
    "    '''Compute the unnormalized posterior from the likelihood and the prior.'''\n",
    "    lnp = lnprior_K2(theta)\n",
    "    return lnp + lnlike_K2(theta, bjd, flux, eflux) if np.isfinite(lnp) else -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_emcee_K2(theta, bjd, flux, eflux, initialize, nwalkers=100, burnin=200, nsteps=200):\n",
    "    '''Run an MCMC on the input K2 light curve modelled with a quasi-periodic Gaussian process.'''\n",
    "    # Initialize walkers in the model parameter space\n",
    "    assert len(theta) == len(initialize)\n",
    "    ndim = len(theta)\n",
    "    p0 = []\n",
    "    for i in range(nwalkers):\n",
    "        p0.append(theta + initialize*np.random.randn(ndim))\n",
    "\n",
    "    # Initialize the emcee sampler\n",
    "    args = (bjd, flux, eflux)\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob_K2, args=args, a=1.9)\n",
    "\n",
    "    # Run the burn-in phase\n",
    "    # I like to time this phase and report the acceptance fraction to gauge how successful the model is\n",
    "    # The acceptance fraction should be between ~ 20-50%\n",
    "    t0 = time.time()\n",
    "    p0,_,_ = sampler.run_mcmc(p0, burnin)\n",
    "    print 'Burn-in mean acceptance fraction is %.4f'%np.mean(sampler.acceptance_fraction)\n",
    "    print 'Burn-in took %.4f minutes\\n'%((time.time()-t0)/60.)\n",
    "    sampler.reset()\n",
    "\n",
    "    # Run the full MCMC after burn-in\n",
    "    p0,_,_ = sampler.run_mcmc(p0, nsteps)\n",
    "    print 'Mean acceptance fraction is %.4f'%np.mean(sampler.acceptance_fraction)\n",
    "    print 'Full MCMC took %.4f minutes\\n'%((time.time()-t0)/60.)\n",
    "\n",
    "    # Return the sampler object (often not needed) and the sampler chains\n",
    "    samples = sampler.chain.reshape((-1, ndim))\n",
    "    return sampler, samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us resample the K2-18 light curve by first ignoring the in-transit points (because they are not a stellar activity effect) and also by reducing the observing cadence to reduce the computation time of the MCMC. Note that although it turns out not to be important in this example, temporal binning can be dangerous as it removes short timescale variations that may be relevant to our stellar activity model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample the K2 photometry\n",
    "fint = interp1d(bjdK2[outtransit], medfilt(flux[outtransit]))\n",
    "bjdK2_resamp = bjdK2[np.arange(0,bjdK2.size,10)]\n",
    "flux_resamp = fint(bjdK2_resamp)\n",
    "eflux_resamp = np.repeat(1e-4, bjdK2_resamp.size)   # arbitrary value set by the short-term scatter in the photometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we provide initial guesses of the GP hyperparameters and run the MCMC to fit the K2-18 light curve with a quasi-periodic GP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the MCMC on the training photometry\n",
    "theta_guess = np.log(1e-3), np.log(80), np.log(1), np.log(40), np.log(1e-6)\n",
    "initialize = np.repeat(.2, len(theta_guess))\n",
    "sampler, samples = run_emcee_K2(theta_guess, bjdK2_resamp, flux_resamp, eflux_resamp, initialize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: save and visualize the training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the samples of the covariance hyperparameters\n",
    "# saved data can be loaded using np.load\n",
    "np.save('output_data/training_posteriors', samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we plot the joint and marginalized posterior distributions of the GP hyperparameters. The posteriors of parameters $\\{ \\ln{\\lambda}, \\ln{\\Gamma}, \\ln{P} \\}$ represent the covariance properties of the temporally correlated stellar activity signal and will therefore be used to inform our stellar activity model in the RVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the joint and marginalized posteriors of the GP hyperparameters\n",
    "theta_results = np.median(samples, axis=0)\n",
    "labels = ['$\\ln{a}$', '$\\ln{\\lambda}$', '$\\ln{\\Gamma}$', '$\\ln{P_{GP}}$', '$s$']\n",
    "_=corner.corner(samples, bins=20, truths=theta_results, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the resampled light curve along with the mean and standard deviation of our GP posterior distribution to ensure that we have obtained a reasonable solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the light curve and the GP model\n",
    "_, bjdpred, mu, sig = phot_model(theta_results, bjdK2_resamp, flux_resamp, eflux_resamp, \n",
    "                                 np.linspace(bjdK2.min(), bjdK2.max(), 1000))\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(bjdK2_resamp-t0, flux_resamp, 'k.', label='resampled photometry')\n",
    "plt.fill_between(bjdpred-t0, mu-sig, mu+sig, color='g', alpha=.5)\n",
    "plt.plot(bjdpred-t0, mu, 'g-', lw=1.3, label='mean GP model')\n",
    "plt.xlabel('Time [BJD - %i]'%t0, fontsize=12)\n",
    "plt.ylabel('Normalized Flux', fontsize=12)\n",
    "plt.legend(loc='upper left', fontsize=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good.\n",
    "\n",
    "## Step 5: begin the RV analysis\n",
    "\n",
    "Now that our GP model has learned the covariance properties of the stellar activity signal from the K2 photometry, we can proceed with modelling the HARPS RVs with planets plus stellar activity. \n",
    "\n",
    "First let's recall the BGLS of the RVs and identify all significant signals that we want to include in our full RV model. Note that in a real analysis this model can and should be modified by considering, for example, different numbers of assumed planets, alternative GP training sets, etc. By considering alternative RV models we relax certain assumptions about the signals in our data and by comparing the results from competing model we can (hopefully) confirm the robustness of our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# periods of interest from the transiting planet, stellar rotation, and the additional signal at 9 days\n",
    "Ps = [32.93963, 38.6, 9]\n",
    "Plabels = ['K2-18b','Prot','K2-18c?']\n",
    "\n",
    "# plot the BGLS\n",
    "per, pwr = bgls.bgls(bjd, rv, erv, plow=.5, phigh=1e3, n_steps=1e3)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(per, np.log(pwr), 'k-')\n",
    "for i,p in enumerate(Ps):\n",
    "    plt.axvline(p, ls='--', lw=.9, color=['b','r','g'][i], label=Plabels[i])\n",
    "plt.xscale('log'), plt.xlabel('Period [days]', fontsize=12)\n",
    "plt.ylabel('p(P|RV)', fontsize=12)\n",
    "plt.legend(loc='upper right', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the peaks around $\\sim$ 33 days can be attributed to stellar rotation and the transiting planet K2-18b. Furthermore, the signal at $\\sim$ 9 days is only seen in the BGLS of the RVs and not in the BGLS of any spectroscopic activity indicators or in its window function (not shown here). In this example we will proceed with assuming that there is a second planet in this system with an orbital period of $\\sim$ 9 days called K2-18c. A complete discussion of the nature of this signal can be found in https://arxiv.org/abs/1810.04731.\n",
    "\n",
    "## Step 6: fit the RVs with a two-planet + a trained GP model\n",
    "\n",
    "Here we define all of the functions needed to compute the full RV model and run an MCMC again using the $\\texttt{emcee}$ package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_RV_model(theta, bjd, rv, erv, bjdpred=[]):\n",
    "    '''Compute the RV model including a GP activity model plus 2 Keplerian planet solutions.'''\n",
    "    # sanity checks\n",
    "    assert len(theta) == 16 # need 16 model parameters {lna,lnlambda,lnGamma,lnP,s,V0,Pb,T0b,Kb,hb,kb,Pc,T0c,Kc,hc,hc}\n",
    "    assert bjd.size == rv.size == erv.size   # all time series vectors must have the same length\n",
    "    assert np.all(np.isfinite(bjd+rv+erv))   # all vector values must be finite (i.e. no NaNs or infs)\n",
    "    \n",
    "    # define the GP prior\n",
    "    agp, lgp, Ggp, Pgp = np.exp(theta[:4])\n",
    "    k_sqexp = george.kernels.ExpSquaredKernel(lgp)    # squared exponential kernel\n",
    "    k_per = george.kernels.ExpSine2Kernel(Ggp, Pgp)   # periodic kernel\n",
    "    gp = george.GP(agp * (k_sqexp + k_per))           # quasi-periodic kernel\n",
    "    \n",
    "    # compute the covariance matrix\n",
    "    try:\n",
    "        s = theta[4]\n",
    "        gp.compute(bjd, np.sqrt(erv**2 + s**2))\n",
    "    except (ValueError, np.linalg.LinAlgError):\n",
    "        return -np.inf\n",
    "    \n",
    "    # compute the planet models\n",
    "    Pb, T0b, Kb, hb, kb = theta[6:11]\n",
    "    _,kepb = kep_model(bjd, (Pb,T0b,0,Kb,hb,kb))\n",
    "    Pc, T0c, Kc, hc, kc = theta[11:]\n",
    "    _,kepc = kep_model(bjd, (Pc,T0c,0,Kc,hc,kc))\n",
    "\n",
    "    # compute the mean and standard deviation of the GP posterior\n",
    "    V0 = theta[5]\n",
    "    bjdpred = bjdpred if len(bjdpred) > 0 else bjd\n",
    "    mu, cov = gp.predict(rv-V0-kepb-kepc, bjdpred)\n",
    "    sig = np.sqrt(np.diag(cov))\n",
    "    \n",
    "    # recompute Keplerians at the new sampling\n",
    "    _,kepb = kep_model(bjdpred, (Pb,T0b,0,Kb,hb,kb))\n",
    "    _,kepc = kep_model(bjdpred, (Pc,T0c,0,Kc,hc,kc))\n",
    "    \n",
    "    return gp, bjdpred, mu, sig, V0, kepb, kepc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnlike_RV(theta, bjd, rv, erv):\n",
    "    '''Compute the ln likelihood of the RVs modelled with a quasi-periodic GP regression model plus two planets.'''\n",
    "    gp,_,_,_,V0,kepb,kepc = full_RV_model(theta, bjd, rv, erv)\n",
    "    return gp.lnlikelihood(rv-V0-kepb-kepc, quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnprior_RV(theta, int_l, int_G, int_P):\n",
    "    '''Compute the prior on the RV model parameters. To adopt an alternate prior on any model parameter will \n",
    "    require modification of this function.'''\n",
    "    # sanity check\n",
    "    assert len(theta) == 16\n",
    "    \n",
    "    # compute the prior for each parameter\n",
    "    lnagp,lnlgp,lnGgp,lnPgp,s,V0,Pb,T0b,Kb,hb,kb,Pc,T0c,Kc,hc,kc = theta\n",
    "    lnpriors = np.zeros(16)\n",
    "    lnpriors[0] = lnuniform(lnagp, -4, 4)\n",
    "    lnpriors[1] = lncustom_int(lnlgp, int_l)\n",
    "    lnpriors[2] = lncustom_int(lnGgp, int_G)\n",
    "    lnpriors[3] = lncustom_int(lnPgp, int_P)\n",
    "    \n",
    "    lnpriors[4] = lnjeffreysprior(s, 1e-2, 10)\n",
    "    lnpriors[5] = lnuniform(V0, 650, 660)\n",
    "    \n",
    "    lnpriors[6] = lngaussian(Pb, 32.93963, 1e-4)\n",
    "    lnpriors[7] = lngaussian(T0b, 2457264.3916, 6e-4)\n",
    "    lnpriors[8] = lnjeffreysprior(Kb, 1, 10)\n",
    "    eb,_ = hk2ew(hb, kb)\n",
    "    lnpriors[9] = lnuniform(hb, -1, 1) if eb < 1 else -np.inf\n",
    "    lnpriors[10] = lnuniform(kb, -1, 1) if eb < 1 else -np.inf\n",
    "\n",
    "    lnpriors[11] = lnuniform(Pc, 6, 12)\n",
    "    lnpriors[12] = lnuniform(T0c, 2457260, 2457272)\n",
    "    lnpriors[13] = lnjeffreysprior(Kc, 1, 10)\n",
    "    ec,_ = hk2ew(hc, kc)\n",
    "    lnpriors[14] = lnuniform(hc, -1, 1) if ec < 1 else -np.inf\n",
    "    lnpriors[15] = lnuniform(kc, -1, 1) if ec < 1 else -np.inf\n",
    "    \n",
    "    # return the prior\n",
    "    return np.sum(lnpriors)\n",
    "\n",
    "\n",
    "\n",
    "def lncustom_int(val, fint):\n",
    "    '''Compute the custom prior given an input interpolator function over the parameter probability from training.'''\n",
    "    try:\n",
    "        return np.log(fint(val))\n",
    "    except ValueError:\n",
    "        return -np.inf\n",
    "    \n",
    "    \n",
    "def lngaussian(val, mean, std):\n",
    "    '''Define the Gaussian prior distribution.'''\n",
    "    return 1/np.sqrt(2*np.pi*std*std) * np.exp(-.5*((val-mean)/std)**2)\n",
    "    \n",
    "    \n",
    "def lnuniform(val, min_val, max_val):\n",
    "    '''Define the uniform prior and return the log of its value.'''\n",
    "    assert max_val > min_val\n",
    "    return 1./(max_val-min_val) if min_val <= val <= max_val else -np.inf\n",
    "\n",
    "\n",
    "def lnjeffreysprior(val, min_val, max_val):\n",
    "    '''Jeffreys prior from Gregory 2005 (see Eq 17). http://adsabs.harvard.edu/abs/2005ApJ...631.1198G'''\n",
    "    assert max_val > min_val\n",
    "    try:\n",
    "        return 1./(val * np.log(max_val/min_val))\n",
    "    except ValueError:\n",
    "        return -np.inf\n",
    "\n",
    "\n",
    "def hk2ew(h, k):\n",
    "    '''Convert the parameters h and k to an eccentricity and argument of periastron.'''\n",
    "    ecc = h*h + k*k\n",
    "    omega = np.arctan2(k, h)\n",
    "    return ecc, omega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnprob_RV(theta, bjd, rv, erv, int_l, int_G, int_P):\n",
    "    '''Compute the unnormalized posterior from the likelihood and prior.'''\n",
    "    lnp = lnprior_RV(theta, int_l, int_G, int_P)\n",
    "    return lnp + lnlike_RV(theta, bjd, rv, erv) if np.isfinite(lnp) else -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_emcee_RV(theta, bjd, flux, eflux, initialize, samplesGP, nwalkers=100, burnin=200, nsteps=200):\n",
    "    '''Run an MCMC on the input RV time series modelled with a trained quasi-periodic Gaussian process \n",
    "    and two planets.'''\n",
    "    # Initialize walkers in the model parameter space\n",
    "    assert len(theta) == len(initialize)\n",
    "    ndim = len(theta)\n",
    "    p0 = []\n",
    "    for i in range(nwalkers):\n",
    "        p0.append(theta + initialize*np.random.randn(ndim))\n",
    "\n",
    "    # construct interpolators for the trained GP hyperparameters\n",
    "    int_l, int_G, int_P = construct_interpolators_lGP(samplesGP)\n",
    "        \n",
    "    # Initialize the emcee sampler\n",
    "    args = (bjd, rv, erv, int_l, int_G, int_P)\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob_RV, args=args, a=1.9)\n",
    "\n",
    "    # Run the burn-in phase\n",
    "    # I like to time this phase and report the acceptance fraction to gauge how successful the model is\n",
    "    t0 = time.time()\n",
    "    p0,_,_ = sampler.run_mcmc(p0, burnin)\n",
    "    print 'Burn-in mean acceptance fraction is %.4f'%np.mean(sampler.acceptance_fraction)\n",
    "    print 'Burn-in took %.4f minutes\\n'%((time.time()-t0)/60.)\n",
    "    sampler.reset()\n",
    "\n",
    "    # Run the full MCMC after burn-in\n",
    "    p0,_,_ = sampler.run_mcmc(p0, nsteps)\n",
    "    print 'Mean acceptance fraction is %.4f'%np.mean(sampler.acceptance_fraction)\n",
    "    print 'Full MCMC took %.4f minutes\\n'%((time.time()-t0)/60.)\n",
    "\n",
    "    # Return the sampler object (often not needed) and the sampler chains\n",
    "    samples = sampler.chain.reshape((-1, ndim))\n",
    "    return sampler, samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the GP hyperparameters in our RV model are informed by their posteriors from training on the K2 photometry, the priors on those parameters need to be interpolated from their respective training posteriors. Note that this process assumes that the three hyperparameters are uncorrelated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_interpolators_lGP(samplesGP):\n",
    "    '''Given the marginalized posteriors of the GP hyperparameters, construct probability interpolators.'''\n",
    "    assert samplesGP.shape[1] == 3\n",
    "    \n",
    "    # get parameter ranges\n",
    "    mins, maxs = np.nanmin(samplesGP, axis=0), np.nanmax(samplesGP, axis=0)\n",
    "    lnlarr = np.linspace(mins[0], maxs[0], 100)\n",
    "    lnGarr = np.linspace(mins[1], maxs[1], 100)\n",
    "    lnParr = np.linspace(mins[2], maxs[2], 100)\n",
    "    \n",
    "    # compute the kernel density estimations\n",
    "    KDE_l = gaussian_kde(samplesGP[:,0]).pdf(lnlarr)\n",
    "    KDE_G = gaussian_kde(samplesGP[:,1]).pdf(lnGarr)\n",
    "    KDE_P = gaussian_kde(samplesGP[:,2]).pdf(lnParr)\n",
    "    \n",
    "    # construct interpolators\n",
    "    int_l = interp1d(lnlarr, KDE_l)\n",
    "    int_G = interp1d(lnGarr, KDE_G)\n",
    "    int_P = interp1d(lnParr, KDE_P)\n",
    "    \n",
    "    return int_l, int_G, int_P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's initialize the model parameters and run the MCMC on the RV time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get GP hyperparameter posteriors from training\n",
    "samplesGP = np.load('output_data/training_posteriors.npy')[:,1:4]  # only want the hyperparameters {lnl, lnG, lnP}\n",
    "\n",
    "# initialize the model parameters\n",
    "theta_guess = np.append(np.log(2), np.median(samplesGP, axis=0))\n",
    "theta_guess = np.append(theta_guess, [1e-1, rv.mean()])\n",
    "theta_guess = np.append(theta_guess, [32.93963, 2457264.39157, 3, 0, 0])\n",
    "theta_guess = np.append(theta_guess, [9, 2457264, 3, 0, 0])\n",
    "\n",
    "# setup the walker initializations\n",
    "initialize = np.repeat(.2, 4)\n",
    "initialize = np.append(initialize, [1e-2, 1e-1])\n",
    "initialize = np.append(initialize, [1e-5, 1e-4, 1e-1, 1e-1, 1e-1])\n",
    "initialize = np.append(initialize, [1, 1, 1e-1, 1e-1, 1e-1])\n",
    "\n",
    "# run the MCMC\n",
    "sampler, samples = run_emcee_RV(theta_guess, bjd, rv, erv, initialize, samplesGP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: save and visualize the results of our RV analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the samples of the RV model parameters\n",
    "np.save('output_data/RV_posteriors', samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the parameter values, and their uncertainties, and plot the joint and marginalized posterior distributions of the RV model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the joint and marginalized posteriors of the GP hyperparameters\n",
    "theta_16th, theta_results, theta_84th = np.percentile(samples, (16,50,84), axis=0)\n",
    "ehi_theta = theta_84th - theta_results\n",
    "elo_theta = theta_results - theta_16th\n",
    "labels = ['$\\ln{a}$','$\\ln{\\lambda}$','$\\ln{\\Gamma}$','$\\ln{P_{GP}}$','$s$','$V_0$',\n",
    "         '$P_b$','$T_{0,b}$','$K_b$','$h_b$','$k_b$',\n",
    "         '$P_c$','$T_{0,c}$','$K_c$','$h_c$','$k_c$']\n",
    "units = ['','','','\\n','m/s','m/s\\n','days','BJD','m/s','','\\n','days','BJD','m/s','','']\n",
    "_=corner.corner(samples, bins=20, truths=theta_results, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The joint and marginalized parameter posteriors depict each parameter's maximum a-posteriori (MAP) value and its uncertainty. Each parameter's uncertainty is often taken from the 16th and 84th percentile of its marginalized posterior. Note however that here we have taken the parameter values to be the median values of their repsective posteriors rather than the MAP values. It is up to the user to decide exactly what point estimates should be used to describe each parameter.\n",
    "\n",
    "The median parameter values and their uncertainties from this analysis are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print parameter point estimates\n",
    "for i in range(theta_results.size):\n",
    "    print r'%s = %.4f + %.4f - %.4f %s'%(labels[i].replace('$',''),theta_results[i],ehi_theta[i],elo_theta[i],units[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we compute the RV models for each of the individual RV model components (i.e. activity, K2-18b, K2-18c) using the median parameter values. We consider both the native HARPS sampling as well as a custom uniform sampling for plotting purposes. Then each RV component is visualized along with its respective BGLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the models with the input sampling and a finer sampling for visualization\n",
    "_,_,mu,sig,V0,kepb,kepc = full_RV_model(theta_results, bjd, rv, erv)\n",
    "_,bjdpred,mupred,sigpred,_,kepbpred,kepcpred = full_RV_model(theta_results, bjd, rv, erv, \n",
    "                                                             np.linspace(bjd.min(), bjd.max(), 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot each RV component and its BGLS\n",
    "RVcomponents = [rv, rv-V0-kepb-kepc, rv-V0-mu-kepc, rv-V0-mu-kepb, rv-V0-mu-kepb-kepc]\n",
    "RVmodels = [None, mupred, kepbpred, kepcpred, np.zeros(bjdpred.size)]\n",
    "RVlabels = ['Raw RVs [m/s]', 'RV Activity [m/s]', 'K2-18b [m/s]', 'K2-18c [m/s]', 'Residuals [m/s]']\n",
    "\n",
    "plt.figure(figsize=(16,14))\n",
    "ind = 0\n",
    "for i in range(5):\n",
    "    \n",
    "    # plot time series and model\n",
    "    plt.subplot(5,2,ind+1+2*i)\n",
    "    plt.errorbar(bjd-t0, RVcomponents[i], erv, fmt='ko', elinewidth=.9)\n",
    "    if i == 1: plt.fill_between(bjdpred-t0, mupred-sigpred, mupred+sigpred, color='c', alpha=.7)\n",
    "    if i > 0: plt.plot(bjdpred-t0, RVmodels[i], '-')\n",
    "    if i == 4: plt.xlabel('Time [BJD - %i]'%t0, fontsize=12)\n",
    "    plt.ylabel(RVlabels[i], fontsize=12)\n",
    "\n",
    "    # plot BGLS\n",
    "    per, pwr = bgls.bgls(bjd, RVcomponents[i], erv, plow=.5, phigh=1e3, n_steps=1e3)\n",
    "    plt.subplot(5,2,ind+2*(1+i))\n",
    "    plt.plot(per, np.log(pwr), 'k-')\n",
    "    for i,p in enumerate(Ps):\n",
    "        plt.axvline(p, ls='--', lw=.9, color=['b','r','g'][i], label=Plabels[i])\n",
    "    plt.xscale('log')\n",
    "    if i == 4: plt.xlabel('Period [days]', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot depicts the raw RVs, the RV stellar activity component, each of the Keplerian planet models, and the RV residuals along with their BGLSs.\n",
    "\n",
    "1) The raw RVs look identifical to the initial visualizations we created when we first read-in the data.<br>\n",
    "\n",
    "2) The stellar activity signal appears to have a relatively low amplitude of a few m/s but with a distinct periodicity of $\\sim$ 40 days. The most significant peak in its BGLS is close to 40 days but still exhibits the forest of peaks around that period due to aliasing with the window function.<br>\n",
    "\n",
    "3) K2-18b has a measured semi-amplitude of 3.1 m/s and exhibits the same forest of peaks in its BGLS due to the promximity of its orbital period of $\\sim$ 33 days to the stellar rotation period of $\\sim$ 40 days.<br>\n",
    "\n",
    "4) K2-18c has a measured semi-amplitude of 3.0 m/s and is clearly the most significant periodic signal in its BGLS indicating that our GP activity model did not absorb much (if any) of that periodic signal.\n",
    "\n",
    "5) The RV residuals are dominated by noise indicating that we have done a satisfactory job of modelling all significant periodic signals in the RV data.\n",
    "\n",
    "Lastly, we phase-fold the activity-corrected data to the orbital periods of the planets to visualize their RV phase curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phase-fold to the planets' orbital periods\n",
    "Pb, T0b = theta_results[6:8]\n",
    "Pc, T0c = theta_results[11:13]\n",
    "phaseb = foldAt(bjd, Pb, T0b)\n",
    "phasec = foldAt(bjd, Pc, T0c)\n",
    "phaseb[phaseb >= .5] -= 1   # shift from the [0,1] domain to [-.5,.5] for clarity\n",
    "phasec[phasec >= .5] -= 1\n",
    "sb = np.argsort(phaseb)\n",
    "sc = np.argsort(phasec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot phase-folded RVs\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.subplot(211)\n",
    "plt.errorbar(phaseb, rv-V0-mu-kepc, erv, fmt='ko', elinewidth=.9)\n",
    "plt.plot(phaseb[sb], kepb[sb], 'b-', lw=2)\n",
    "plt.ylim((-15,15))\n",
    "plt.ylabel('K2-18b RVs [m/s]', fontsize=12)\n",
    "plt.xlabel('Orbital Phase (P=%.5f days)'%Pb, fontsize=12)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.errorbar(phasec, rv-V0-mu-kepb, erv, fmt='ko', elinewidth=.9)\n",
    "plt.plot(phasec[sc], kepc[sc], 'g-', lw=2)\n",
    "plt.ylim((-15,15))\n",
    "plt.ylabel('K2-18c RVs [m/s]', fontsize=12)\n",
    "plt.xlabel('Orbital Phase (P=%.3f days)'%Pc, fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: derive physical planet parameters of interest\n",
    "\n",
    "Now that we have measured the planet parameters from our RV analysis, we can derive some planet parameters of interest given our knowledge of the star."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_planetmass(P_days, Ms_MSun, K_ms):\n",
    "    '''Compute the planet mass (in Earth masses) assuming the planet's orbit is circular and oriented edge-on.'''\n",
    "    K_Earth_ms = 0.0894590658\n",
    "    return (K_ms/K_Earth_ms) * Ms_MSun**(2./3) * (P_days/365.)**(1./3)\n",
    "\n",
    "def compute_bulkdensity(mp_MEarth, rp_REarth):\n",
    "    '''Compute the planet's bulk density.'''\n",
    "    return 5.55 * mp_MEarth / rp_REarth**3\n",
    "\n",
    "def compute_sma(P_days, Ms_MSun):\n",
    "    '''Compute the planet's semimajor axis.'''\n",
    "    return (P_days/365.)**(2./3) * Ms_MSun**(1./3)\n",
    "\n",
    "def compute_Teq(sma_AU, Teff_K, Rs_RSun, A=0.3):\n",
    "    '''Compute the planet's equilibrium temperature.'''\n",
    "    return 254.8 * ((1.-A)/.7)**(1./4) * (Teff_K/5777.) * (Rs_RSun/sma_AU)**(1./2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define known parameters and uncertainties\n",
    "Ms = unp.uarray(.495, .004)    # K2-18 mass [Solar masses]\n",
    "Rs = unp.uarray(.469, .010)    # K2-18 radius [Solar radii]\n",
    "Teff = unp.uarray(3503, 60)    # K2-18 effective temperature [K]\n",
    "rpb = unp.uarray(2.711, .065)  # K2-18b radius [Earth radii]\n",
    "\n",
    "# define measured parameters and uncertainties\n",
    "Pb = unp.uarray(theta_results[6], np.mean([ehi_theta[6], elo_theta[6]]))  # measured orbital period\n",
    "Kb = unp.uarray(theta_results[8], np.mean([ehi_theta[8], elo_theta[8]]))  # measured semi-amplitude\n",
    "Pc = unp.uarray(theta_results[11], np.mean([ehi_theta[11], elo_theta[11]]))  # measured orbital period\n",
    "Kc = unp.uarray(theta_results[13], np.mean([ehi_theta[13], elo_theta[13]]))  # measured semi-amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derive planetary parameters of interest\n",
    "mpb, mpc = compute_planetmass(Pb, Ms, Kb), compute_planetmass(Pc, Ms, Kc)\n",
    "rhob = compute_bulkdensity(mpb, rpb)\n",
    "smab, smac = compute_sma(Pb, Ms), compute_sma(Pc, Ms)\n",
    "Teqb, Teqc = compute_Teq(smab, Teff, Rs), compute_Teq(smac, Teff, Rs)\n",
    "params = [mpb, mpc, rhob, smab, smac, Teqb, Teqc]\n",
    "labels = ['m_{p,b}','m_{p,c}','rho_{p,b}','a_{p,b}','a_{p,c}','T_{eq,b}','T_{eq,c}']\n",
    "units = ['Earth masses','Earth masses\\n','g/cm^3\\n','AU','AU\\n','K','K']\n",
    "\n",
    "for i in range(len(params)):\n",
    "    print r'%s = %.4f +- %.4f %s'%(labels[i], unp.nominal_values(params[i]), unp.std_devs(params[i]), units[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it, you've completed your RV analysis. Take caution though that some alternate analyses should be considered for instance using alternative tranining sets to the photometry, perhaps not training the GP at all, and considering models with differing numbers of planets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
